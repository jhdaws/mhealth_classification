{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMAkyc2djQNG4CftJib5eCM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Loading Data"],"metadata":{"id":"9hpJ4gJDXAKt"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304},"collapsed":true,"id":"xrf3j-vs-nHY","executionInfo":{"status":"error","timestamp":1750802878864,"user_tz":420,"elapsed":121628,"user":{"displayName":"Jack Dawson","userId":"00187716055514319323"}},"outputId":"a2f1ee08-e2f1-4a72-eae9-c06889865c82"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"mount failed","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         )\n\u001b[0;32m--> 279\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: mount failed"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from xgboost import XGBClassifier\n","from sklearn.model_selection import StratifiedGroupKFold, cross_val_score, RandomizedSearchCV, GridSearchCV, TunedThresholdClassifierCV, cross_validate\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix, roc_curve, ConfusionMatrixDisplay, precision_recall_curve, average_precision_score, make_scorer, f1_score, precision_score, recall_score\n","from sklearn.metrics import get_scorer_names, balanced_accuracy_score\n","import matplotlib.pyplot as plt\n","from typing_extensions import final\n","from sklearn.ensemble import RandomForestClassifier\n","import seaborn as sns"],"metadata":{"id":"cl7o7im2Tye-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Option 1"],"metadata":{"id":"HilNWb-Aaedc"}},{"cell_type":"code","source":["# Patient has visit -> all days are 1\n","fitbit_data = pd.read_csv('/content/drive/My Drive/colab_data/data_daily_w_visits.csv')\n","\n","# Loop through each user group\n","for user_id, group in fitbit_data.groupby('fitbit_user_id'):\n","    if (group['visit_day'] == 1).any():\n","        # Set all rows for this user to 1 in the original dataframe\n","        fitbit_data.loc[fitbit_data['fitbit_user_id'] == user_id, 'visit_day'] = 1"],"metadata":{"id":"weUapUeZ6f8t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Option 2"],"metadata":{"id":"SCCb6moNaiSP"}},{"cell_type":"code","source":["# Load your data\n","fitbit_data = pd.read_csv('/content/drive/My Drive/colab_data/data_daily_w_visits.csv')\n","\n","# Iterate by user\n","for user_id, group in fitbit_data.groupby('fitbit_user_id'):\n","    visit_days = group[group['visit_day'] == 1]['days'].values\n","\n","    for visit_day in visit_days:\n","        # Get range from (visit_day - 14) to (visit_day + 14)\n","        lower = visit_day - 14\n","        upper = visit_day + 14\n","\n","        # Create mask for the affected rows for this user\n","        mask = (\n","            (fitbit_data['fitbit_user_id'] == user_id) &\n","            (fitbit_data['days'] >= lower) &\n","            (fitbit_data['days'] <= upper)\n","        )\n","\n","        fitbit_data.loc[mask, 'visit_day'] = 1"],"metadata":{"id":"OmJ6tLJb7q8m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ensure date is datetime and sort\n","fitbit_data['date'] = pd.to_datetime(fitbit_data['date'])\n","fitbit_data = fitbit_data.sort_values(by=['fitbit_user_id', 'date'])"],"metadata":{"id":"Rc1893s7KJMP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Organizing columns\n","measure_cols = ['avgWeight_per_day', 'calories', 'heart', 'steps']\n","survey_cols = ['diet', 'medication', 'symptoms']\n","result_col = 'visit_day'"],"metadata":{"id":"8Y1k1dgqLXTO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fitbit_data[result_col] = fitbit_data[result_col].fillna(0)"],"metadata":{"id":"UQ9d9_aaT1HF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def fix_survey_cols(df, cols):\n","    df = df.copy()\n","\n","    # Shift survey columns backward by one day within each user group\n","    for col in cols:\n","        df[f'{col}_cur'] = df.groupby('fitbit_user_id')[col].shift(-1)\n","\n","    return df\n","\n","fitbit_data = fix_survey_cols(fitbit_data, survey_cols)"],"metadata":{"id":"US6Dq46bSvcO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["survey_cols = ['diet_cur', 'medication_cur', 'symptoms_cur']"],"metadata":{"id":"2gPG3roTba_h"},"execution_count":null,"outputs":[]},{"source":["# Clears rows with empty columns to start\n","def prelim_row_removal(df, cols):\n","    cleaned_groups = []\n","\n","    for _, group in df.groupby('fitbit_user_id'):\n","        group = group.copy()\n","        to_remove = []\n","\n","        for idx, row in group.iterrows():\n","            if row[cols].isna().all() and row['study_group'] != \"No App\":\n","                to_remove.append(idx)\n","            else:\n","                break  # Stop as soon as we hit a row with any non-NaN value\n","\n","        group = group.drop(index=to_remove)\n","        cleaned_groups.append(group)\n","\n","    return pd.concat(cleaned_groups).reset_index(drop=True)\n","\n","\n","fitbit_data = prelim_row_removal(fitbit_data, measure_cols+survey_cols)"],"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"cellView":"form","id":"RsKbEar_yzFD","collapsed":true}},{"cell_type":"code","source":["def mark_day_for_removal(df, cols, max_nans, window):\n","    df = df.copy()\n","    df['remove'] = False\n","\n","    for _, group in df.groupby('fitbit_user_id'):\n","        group = group.copy()\n","\n","        for col in cols:\n","            n = len(group)\n","            for start in range(n):\n","                end = min(start + window, n)\n","                window_slice = group.iloc[start:end]\n","\n","                # Count NaNs in this window for this column\n","                nan_count = window_slice[col].isna().sum()\n","\n","                if nan_count >= max_nans:\n","                    # Mark rows with NaN in this column for removal\n","                    for idx in window_slice.index:\n","                        if pd.isna(group.at[idx, col]):\n","                            df.at[idx, 'remove'] = True\n","\n","    return df\n","\n","fitbit_data = mark_day_for_removal(fitbit_data, measure_cols+survey_cols, 3, 7)"],"metadata":{"id":"22LgjEPQZif4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def impute_forward_fill(df, cols):\n","    df = df.copy()\n","    for _, group in df.groupby('fitbit_user_id'):\n","        group = group.copy()\n","        for col in cols:\n","            group[col] = group[col].ffill()  # forward fill\n","        df.loc[group.index, cols] = group[cols]\n","    return df\n","\n","fb_data = impute_forward_fill(fitbit_data, measure_cols+survey_cols)"],"metadata":{"id":"o5TEUeQTZse5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def one_hot_encode_with_nan(df, cols):\n","    df = df.copy()\n","    for col in cols:\n","        dummies = pd.get_dummies(df[col], prefix=col)\n","\n","        # Set dummy rows to np.nan where original was NaN\n","        dummies[df[col].isna()] = np.nan\n","\n","        # Convert dummies to float so XGBoost can handle them\n","        dummies = dummies.astype(float)\n","\n","        df = pd.concat([df, dummies], axis=1)\n","        df.drop(columns=[col], inplace=True)\n","    return df\n","\n","fb_data = one_hot_encode_with_nan(fb_data, survey_cols)"],"metadata":{"id":"Uj7G0DUHT6hV","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["oneh_cols = ['diet_cur_0.0', 'diet_cur_1.0', 'diet_cur_2.0', 'medication_cur_0.0', 'medication_cur_1.0', 'medication_cur_2.0', 'symptoms_cur_0.0', 'symptoms_cur_1.0', 'symptoms_cur_2.0']"],"metadata":{"id":"WIK1fiAT1zUX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def final_clean(df, cols):\n","    df = df.copy()\n","\n","    # Remove rows marked True in the 'remove' column\n","    df = df[df['remove'] != True]\n","\n","    # Remove rows that have any NaN in the specified columns\n","    df = df.dropna(subset=cols)\n","\n","    return df\n","\n","fb_data = final_clean(fb_data, measure_cols+oneh_cols)"],"metadata":{"id":"LDRXN0UMaBe_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scaler = MinMaxScaler().fit(fb_data[measure_cols])\n","fb_data[measure_cols] = scaler.transform(fb_data[measure_cols])"],"metadata":{"id":"nE8F9pCIhsTP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fb_data"],"metadata":{"collapsed":true,"id":"ruOXdO8QeEIo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## KFold Cross Validation"],"metadata":{"id":"sxn84vqcW9tz"}},{"cell_type":"code","source":["x = fb_data[measure_cols+oneh_cols+['fitbit_user_id']]\n","targets = fb_data[result_col].astype(int)\n","\n","sgkf = StratifiedGroupKFold(n_splits=5)\n","\n","groups = x['fitbit_user_id']  # or however you track user grouping"],"metadata":{"id":"ZkuWXuaAXUng"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rf = RandomForestClassifier(random_state=42, n_jobs=-1)"],"metadata":{"id":"kTJpT6Wjt0Pf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cross_val_score(rf, x, targets, groups=groups, cv=sgkf, scoring=\"roc_auc\")"],"metadata":{"id":"Eo3tf1Q4plI0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cross_val_score(rf, x, targets, groups=groups, cv=sgkf, scoring=\"average_precision\")"],"metadata":{"id":"COw-qGIqtF15"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cross_val_score(rf, x, targets, groups=groups, cv=sgkf, scoring=\"f1\")"],"metadata":{"id":"z6ednYSatqBr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Tuning Hyperparameters"],"metadata":{"id":"V_duzO29Flaz"}},{"cell_type":"code","source":["# Broad parameter space\n","param_dist_rf = {\n","    'n_estimators': [100, 200, 300, 400],\n","    'max_depth': [None, 10, 20, 30],\n","    'max_features': ['sqrt', 'log2', None],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4],\n","    'bootstrap': [True, False]\n","}\n","\n","rf_random_search = RandomizedSearchCV(\n","    estimator=rf,\n","    param_distributions=param_dist_rf,\n","    n_iter=30,\n","    scoring='roc_auc',\n","    n_jobs=-1,\n","    cv=sgkf.split(x, targets, groups=groups),\n","    verbose=1,\n","    random_state=42\n",")\n","\n","rf_random_search.fit(x, targets, groups=groups)\n","\n","print(\"Best params:\", rf_random_search.best_params_)\n","print(\"Best ROC AUC:\", rf_random_search.best_score_)"],"metadata":{"id":"m8TTNGg0GiRt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["param_grid_rf = {\n","    'n_estimators': [150, 200, 250],\n","    'max_depth': [5, 10, 15],\n","    'min_samples_split': [4, 5, 6],\n","    'min_samples_leaf': [3, 4, 5],\n","    'max_features': ['sqrt'],\n","    'bootstrap': [True]\n","}\n","\n","rf_grid_search = GridSearchCV(\n","    estimator=rf,\n","    param_grid=param_grid_rf,\n","    scoring='roc_auc',\n","    n_jobs=-1,\n","    cv=sgkf.split(x, targets, groups=groups),\n","    verbose=1\n",")\n","\n","rf_grid_search.fit(x, targets, groups=groups)\n","\n","print(\"Best RF grid params:\", rf_grid_search.best_params_)\n","print(\"Best RF grid ROC AUC:\", rf_grid_search.best_score_)"],"metadata":{"collapsed":true,"id":"BGBc17KQ5xN-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ROC Curves + Confusion Matricies"],"metadata":{"id":"DUxVQUoq5j9b"}},{"cell_type":"code","source":["best_params_week = {'min_samples_split': 5, 'n_estimators': 200, 'min_sample_leaf': 4, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': True}\n","best_params_user = {'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 20, 'bootstrap': True}"],"metadata":{"id":"C6xzKZ7i1VxO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_evaluate_visualize(X_train, y_train, X_val, y_val, **params):\n","    model = RandomForestClassifier(random_state=42, n_jobs=-1, **params)\n","    model.fit(X_train, y_train)\n","\n","    # Hard predictions\n","    y_pred_train = model.predict(X_train)\n","    y_pred_val   = model.predict(X_val)\n","\n","    # Probabilities for ROC/AUC\n","    y_prob_train = model.predict_proba(X_train)[:, 1]\n","    y_prob_val   = model.predict_proba(X_val)[:, 1]\n","\n","    # Metrics\n","    train_acc = accuracy_score(y_train, y_pred_train)\n","    val_acc   = accuracy_score(y_val, y_pred_val)\n","    train_auc = roc_auc_score(y_train, y_prob_train)\n","    val_auc   = roc_auc_score(y_val, y_prob_val)\n","\n","    print(f\"Train  Acc: {train_acc:.3f},  Validation Acc: {val_acc:.3f}\")\n","    print(f\"Train  AUC: {train_auc:.3f},  Validation AUC: {val_auc:.3f}\")\n","\n","    # Confusion Matrix\n","    cm = confusion_matrix(y_val, y_pred_val)\n","    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","    disp.plot(cmap=\"Blues\")\n","    plt.title(\"Confusion Matrix\")\n","    plt.show()\n","\n","    # ROC Curve\n","    fpr, tpr, _ = roc_curve(y_val, y_prob_val)\n","    plt.figure()\n","    plt.plot(fpr, tpr, label=f'ROC (AUC = {val_auc:.2f})')\n","    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n","    plt.xlabel(\"False Positive Rate\")\n","    plt.ylabel(\"True Positive Rate\")\n","    plt.title(\"ROC Curve\")\n","    plt.legend(loc=\"lower right\")\n","    plt.grid(True)\n","    plt.show()\n","\n","    # Precision-Recall Curve\n","    precision, recall, _ = precision_recall_curve(y_val, y_prob_val)\n","    avg_precision = average_precision_score(y_val, y_prob_val)\n","    plt.figure()\n","    plt.plot(recall, precision, label=f'PR Curve (AP = {avg_precision:.2f})')\n","    plt.xlabel(\"Recall\")\n","    plt.ylabel(\"Precision\")\n","    plt.title(\"Precision-Recall Curve\")\n","    plt.legend(loc=\"lower left\")\n","    plt.grid(True)\n","    plt.show()\n","\n","    return model, train_acc, val_acc, train_auc, val_auc"],"metadata":{"id":"-_5AWCZQgiTm","executionInfo":{"status":"ok","timestamp":1750875798133,"user_tz":420,"elapsed":26,"user":{"displayName":"Jack Dawson","userId":"00187716055514319323"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["modelsSGK = []\n","for train_idx, val_idx in sgkf.split(x, targets, groups=groups):\n","    X_tr, y_tr = x.iloc[train_idx], targets.iloc[train_idx]\n","    X_vl, y_vl = x.iloc[val_idx], targets.iloc[val_idx]\n","\n","    model, train_acc, val_acc, train_auc, val_auc = train_evaluate_visualize(\n","        X_tr, y_tr,\n","        X_vl, y_vl,\n","        **best_params_user\n","    )\n","\n","    modelsSGK.append(model)"],"metadata":{"collapsed":true,"id":"TMSiRg41iHIZ","executionInfo":{"status":"error","timestamp":1750875804323,"user_tz":420,"elapsed":224,"user":{"displayName":"Jack Dawson","userId":"00187716055514319323"}},"colab":{"base_uri":"https://localhost:8080/","height":211},"outputId":"3d605a99-2720-4392-df4b-c1c133f18277"},"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'sgkf' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2-1373302084.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodelsSGK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msgkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mX_vl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_vl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'sgkf' is not defined"]}]},{"cell_type":"code","source":["best_params = {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': True}"],"metadata":{"id":"y0TvAHU03sAF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define model with best parameters\n","rf_res = RandomForestClassifier(random_state=42, n_jobs=-1, **best_params_user)\n","\n","# Define scoring metrics\n","scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n","\n","# Run CV\n","cv_results = cross_validate(\n","    rf_res,\n","    x,\n","    targets,\n","    groups=groups,\n","    cv=sgkf,\n","    scoring=scoring,\n","    return_train_score=True\n",")"],"metadata":{"id":"p8Xrl0Hf1Ul-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert to DataFrame\n","cv_df = pd.DataFrame(cv_results)\n","\n","# Clean summary table\n","summary = cv_df[[col for col in cv_df.columns if col.startswith('test_')]].describe().T\n","summary['metric'] = summary.index.str.replace('test_', '')\n","summary = summary[['metric', 'mean', 'std']]\n","summary.reset_index(drop=True, inplace=True)\n","\n","summary"],"metadata":{"id":"pbxlQP0l18lq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Only test metrics\n","metric_data = {k: v for k, v in cv_results.items() if k.startswith('test_')}\n","metric_df = pd.DataFrame(metric_data)\n","\n","# Rename for clarity\n","metric_df.columns = [col.replace('test_', '') for col in metric_df.columns]\n","metric_df = metric_df.melt(var_name='Metric', value_name='Score')\n","\n","# Boxplot\n","plt.figure(figsize=(8, 5))\n","sns.boxplot(data=metric_df, x='Metric', y='Score')\n","plt.title(\"Cross-Validation Metric Distribution (Test Sets)\")\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"2Hz8czXb2H2j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_test_df = pd.DataFrame({\n","    'Train Accuracy': cv_results['train_accuracy'],\n","    'Test Accuracy': cv_results['test_accuracy'],\n","    'Train AUC': cv_results['train_roc_auc'],\n","    'Test AUC': cv_results['test_roc_auc']\n","})\n","\n","train_test_df.plot(kind='bar', figsize=(10, 5))\n","plt.title(\"Train vs Test Scores per Fold\")\n","plt.ylabel(\"Score\")\n","plt.xticks(rotation=0)\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"z-rdKzuy2OAu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Tuning threshold"],"metadata":{"id":"kNW1w6_xP8HU"}},{"cell_type":"code","source":["for train_idx, val_idx in sgkf.split(x, targets, groups):\n","    X_train, X_val = x.iloc[train_idx], x.iloc[val_idx]\n","    y_train, y_val = targets.iloc[train_idx], targets.iloc[val_idx]\n","    groups_train = groups.iloc[train_idx]\n","    break"],"metadata":{"id":"uK5QSYh0QALs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rf = RandomForestClassifier(\n","    **best_params_user,\n","    random_state=42,\n","    n_jobs=-1,\n",")\n","\n","rf_thresh = TunedThresholdClassifierCV(\n","    estimator=rf,\n","    scoring=\"balanced_accuracy\",\n","    store_cv_results=True,\n","    cv=StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42).split(\n","        X_train, y_train, groups_train\n","    ),\n","    thresholds = 200,\n","    refit=True\n",")\n","\n","rf_thresh.fit(X_train, y_train)\n","\n","# --- Best threshold found ---\n","best_threshold = rf_thresh.best_threshold_\n","print(f\"✅ Tuned threshold: {best_threshold:.3f}\")\n"],"metadata":{"id":"28z4ugkGQCb8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(\n","    rf_thresh.cv_results_[\"thresholds\"],\n","    rf_thresh.cv_results_[\"scores\"],\n","    label=\"accuracy\"\n",")\n","plt.plot(\n","    rf_thresh.best_threshold_,\n","    rf_thresh.best_score_,\n","    \"o\",\n","    markersize = 10,\n","    color =\"tab:orange\",\n","    label=\"Optimal cut off point\"\n",")\n","plt.legend()\n"],"metadata":{"id":"u2A5s_wYQFjs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred_val = rf_thresh.predict(X_val)\n","\n","cm = confusion_matrix(y_val, y_pred_val)\n","print(\"Confusion Matrix on Validation Set:\\n\", cm)"],"metadata":{"id":"NlClF2ULQI-A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Model definition ---\n","model = RandomForestClassifier(\n","   **best_params_user,\n","    random_state=42,\n","    n_jobs=-1\n",")\n","\n","# --- Wrapper for threshold tuning ---\n","tuned_model = TunedThresholdClassifierCV(\n","    estimator=model,\n","    scoring=\"balanced_accuracy\",\n","    store_cv_results=True,\n","    thresholds=200,  # granularity of threshold search\n","    refit=True\n",")\n","\n","# --- Cross-validate outer loop ---\n","cv = StratifiedGroupKFold(n_splits=10, shuffle=True, random_state=42)\n","scoring = {\n","    \"balanced_accuracy\": make_scorer(balanced_accuracy_score),\n","    \"f1\": make_scorer(f1_score),\n","    \"accuracy\": \"accuracy\",\n","    \"roc_auc\": \"roc_auc\"\n","}\n","\n","cv_results_tuned_model = pd.DataFrame(\n","    cross_validate(\n","        tuned_model,\n","        x,          # your features\n","        targets,        # your binary labels\n","        groups=groups,  # same group used in StratifiedGroupKFold\n","        scoring=scoring,\n","        cv=cv,\n","        return_train_score=True,\n","        return_estimator=True\n","    )\n",")\n","\n","# --- Summary of scores ---\n","cv_results_tuned_model[\n","    [col for col in cv_results_tuned_model.columns if \"test\" in col]\n","].aggregate([\"mean\", \"std\"]).T"],"metadata":{"id":"k6RYsx0FnfKl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["thresholds = [est.best_threshold_ for est in cv_results_tuned_model[\"estimator\"]]\n","\n","# Mean (sensitive to outliers)\n","mean_threshold = np.mean(thresholds)\n","\n","# Median (robust to outliers)\n","median_threshold = np.median(thresholds)\n","\n","# Trimmed mean: excludes lowest/highest 10%\n","from scipy.stats import trim_mean\n","trimmed_threshold = trim_mean(thresholds, proportiontocut=0.1)\n","\n","print(f\"Mean threshold:     {mean_threshold:.3f}\")\n","print(f\"Median threshold:   {median_threshold:.3f}\")\n","print(f\"Trimmed threshold:  {trimmed_threshold:.3f}\")"],"metadata":{"id":"67Twe6QCwV7v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.hist(thresholds, bins=10)\n","plt.axvline(mean_threshold, color='blue', linestyle='--', label='Mean Threshold')\n","plt.axvline(trimmed_threshold, color='red', linestyle='--', label='Trim Threshold')\n","plt.axvline(median_threshold, color='green', linestyle='--', label='Median Threshold')\n","plt.xlabel(\"Best Thresholds per Fold\")\n","plt.ylabel(\"Frequency\")\n","plt.title(\"Distribution of Tuned Thresholds\")\n","plt.legend()\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"ZBeElsEsswqW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Evaluating Threshold"],"metadata":{"id":"WfhVs6WVTnQx"}},{"cell_type":"code","source":["best_threshold = 0.04"],"metadata":{"id":"4Ju-NkKxw5FH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_evaluate_threshold(X_train, y_train, X_val, y_val, **params):\n","    model = RandomForestClassifier(random_state=42, n_jobs=-1, **params)\n","    model.fit(X_train, y_train)\n","\n","    # Probabilities\n","    y_prob_train = model.predict_proba(X_train)[:, 1]\n","    y_prob_val   = model.predict_proba(X_val)[:, 1]\n","\n","    # Apply threshold\n","    y_pred_train = (y_prob_train >= best_threshold).astype(int)\n","    y_pred_val   = (y_prob_val >= best_threshold).astype(int)\n","\n","    # Metrics\n","    train_acc = accuracy_score(y_train, y_pred_train)\n","    val_acc   = accuracy_score(y_val, y_pred_val)\n","    train_auc = roc_auc_score(y_train, y_prob_train)\n","    val_auc   = roc_auc_score(y_val, y_prob_val)\n","\n","    train_precision = precision_score(y_train, y_pred_train, zero_division=0)\n","    val_precision   = precision_score(y_val, y_pred_val, zero_division=0)\n","    train_recall    = recall_score(y_train, y_pred_train, zero_division=0)\n","    val_recall      = recall_score(y_val, y_pred_val, zero_division=0)\n","    train_f1        = f1_score(y_train, y_pred_train, zero_division=0)\n","    val_f1          = f1_score(y_val, y_pred_val, zero_division=0)\n","\n","    avg_precision = average_precision_score(y_val, y_prob_val)\n","\n","    # Confusion matrix\n","    cm = confusion_matrix(y_val, y_pred_val)\n","    tn, fp, fn, tp = cm.ravel()\n","    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n","    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n","\n","    print(\"Threshold Used:\", best_threshold)\n","    print(\"Train Accuracy: {:.3f}, Validation Accuracy: {:.3f}\".format(train_acc, val_acc))\n","    print(\"Train AUC: {:.3f},     Validation AUC: {:.3f}\".format(train_auc, val_auc))\n","    print(\"Train F1: {:.3f},      Validation F1: {:.3f}\".format(train_f1, val_f1))\n","    print(\"Train Precision: {:.3f}, Validation Precision: {:.3f}\".format(train_precision, val_precision))\n","    print(\"Train Recall: {:.3f},    Validation Recall: {:.3f}\".format(train_recall, val_recall))\n","    print(\"Validation AP Score: {:.3f}\".format(avg_precision))\n","    print(\"Validation Sensitivity (TPR): {:.3f}\".format(sensitivity))\n","    print(\"Validation Specificity (TNR): {:.3f}\".format(specificity))\n","    print(\"Confusion Matrix:\")\n","    print(cm)\n","\n","    return {\n","        \"model\": model,\n","        \"train_acc\": train_acc,\n","        \"val_acc\": val_acc,\n","        \"train_auc\": train_auc,\n","        \"val_auc\": val_auc,\n","        \"train_f1\": train_f1,\n","        \"val_f1\": val_f1,\n","        \"train_precision\": train_precision,\n","        \"val_precision\": val_precision,\n","        \"train_recall\": train_recall,\n","        \"val_recall\": val_recall,\n","        \"val_ap\": avg_precision,\n","        \"val_sensitivity\": sensitivity,\n","        \"val_specificity\": specificity,\n","        \"conf_matrix\": cm\n","    }\n"],"metadata":{"id":"FfybzN-XTqkq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results = []\n","\n","for train_idx, val_idx in sgkf.split(x, targets, groups=groups):\n","    X_tr, y_tr = x.iloc[train_idx], targets.iloc[train_idx]\n","    X_vl, y_vl = x.iloc[val_idx], targets.iloc[val_idx]\n","\n","    res = train_evaluate_threshold(\n","        X_tr, y_tr,\n","        X_vl, y_vl,\n","        **best_params_user\n","    )\n","\n","    results.append(res)\n","\n","metrics_df = pd.DataFrame([\n","    {\n","        \"Train Acc\": r[\"train_acc\"],\n","        \"Val Acc\": r[\"val_acc\"],\n","        \"Train AUC\": r[\"train_auc\"],\n","        \"Val AUC\": r[\"val_auc\"],\n","        \"Val F1\": r[\"val_f1\"],\n","        \"Val Precision\": r[\"val_precision\"],\n","        \"Val Recall\": r[\"val_recall\"],\n","        \"Val AP\": r[\"val_ap\"],\n","        \"Val Sensitivity\": r[\"val_sensitivity\"],\n","        \"Val Specificity\": r[\"val_specificity\"]\n","    }\n","    for r in results\n","])\n","\n","# Show summary statistics\n","summary_stats = metrics_df.describe().T\n","print(\"=== Summary Stats ===\")\n","print(summary_stats)\n","\n","# Show boxplot of performance across folds\n","plt.figure(figsize=(12, 6))\n","sns.boxplot(data=metrics_df)\n","plt.title(\"Cross-Validation Performance Metrics\")\n","plt.xticks(rotation=45)\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n","\n","plt.figure(figsize=(12, 6))\n","for col in [\"Val F1\", \"Val AUC\", \"Val Precision\", \"Val Recall\"]:\n","    plt.plot(metrics_df.index, metrics_df[col], marker='o', label=col)\n","\n","plt.title(\"Validation Metrics Across Folds\")\n","plt.xlabel(\"Fold\")\n","plt.ylabel(\"Score\")\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n"],"metadata":{"id":"LZT5QmAfTs91","collapsed":true},"execution_count":null,"outputs":[]}]}